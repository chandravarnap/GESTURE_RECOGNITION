{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.pyplot import imread\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import abc\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.1+nv)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.9999+nv)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: absl-py<0.11.0,>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: nvidia-tensorboard in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.3.0+nv20.11)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->nvidia-tensorboard->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('datasets/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('datasets/Project_data/val.csv').readlines())\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height\n",
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [x for x in range(0,x)] #create a list of image numbers you want to use for a particular video\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    temp = imresize(image,(120,120))\n",
    "                    temp = temp/127.5-1 #Normalize data\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (temp[:,:,0]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = (temp[:,:,1]) #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (temp[:,:,2]) #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            print(\"Batch: \",num_batches+1,\"Index:\", batch_size)\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): \n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    temp = imresize(image,(120,120))\n",
    "                    temp = temp/127.5-1 #Normalize data\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (temp[:,:,0])\n",
    "                    batch_data[folder,idx,:,:,1] = (temp[:,:,1])\n",
    "                    batch_data[folder,idx,:,:,2] = (temp[:,:,2])\n",
    "                   \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 10\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = 'datasets/Project_data/train'\n",
    "val_path = 'datasets/Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 10 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.17.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "import keras\n",
    "\n",
    "\n",
    "#write your model here\n",
    "#model a\n",
    "model_a = Sequential()\n",
    "\n",
    "model_a.add(Conv3D(8, #number of filters \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=(30, 120, 120, 3),\n",
    "                 padding='same'))\n",
    "model_a.add(BatchNormalization())\n",
    "model_a.add(Activation('relu'))\n",
    "\n",
    "model_a.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_a.add(Conv3D(16, #Number of filters, \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_a.add(BatchNormalization())\n",
    "model_a.add(Activation('relu'))\n",
    "\n",
    "model_a.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_a.add(Conv3D(32, #Number of filters \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_a.add(BatchNormalization())\n",
    "model_a.add(Activation('relu'))\n",
    "\n",
    "model_a.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_a.add(Conv3D(64, #Number pf filters \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_a.add(BatchNormalization())\n",
    "model_a.add(Activation('relu'))\n",
    "\n",
    "model_a.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_a.add(Flatten())\n",
    "\n",
    "model_a.add(Dense(1000, activation='relu'))\n",
    "model_a.add(Dropout(0.5))\n",
    "\n",
    "model_a.add(Dense(500, activation='relu'))\n",
    "model_a.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_a.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,749\n",
      "Trainable params: 3,667,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam(lr=0.001) #write your optimizer\n",
    "model_a.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_a.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-6585558018ac>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Source path =  datasets/Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n",
      "65/67 [============================>.] - ETA: 2s - loss: 4.8828 - categorical_accuracy: 0.2646Batch:  67 Index: 10\n",
      "67/67 [==============================] - ETA: 0s - loss: 4.8181 - categorical_accuracy: 0.2670Source path =  datasets/Project_data/val ; batch size = 10\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0516_22_40.984452/model-00001-4.81811-0.26697-1.99632-0.25000.h5\n",
      "67/67 [==============================] - 90s 1s/step - loss: 4.8181 - categorical_accuracy: 0.2670 - val_loss: 1.9963 - val_categorical_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.3171 - categorical_accuracy: 0.3134\n",
      "Epoch 00002: saving model to model_init_2021-07-0516_22_40.984452/model-00002-2.31711-0.31343-2.03804-0.30000.h5\n",
      "67/67 [==============================] - 38s 567ms/step - loss: 2.3171 - categorical_accuracy: 0.3134 - val_loss: 2.0380 - val_categorical_accuracy: 0.3000\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.8307 - categorical_accuracy: 0.2289\n",
      "Epoch 00003: saving model to model_init_2021-07-0516_22_40.984452/model-00003-1.83071-0.22886-1.38461-0.45000.h5\n",
      "67/67 [==============================] - 39s 578ms/step - loss: 1.8307 - categorical_accuracy: 0.2289 - val_loss: 1.3846 - val_categorical_accuracy: 0.4500\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.7293 - categorical_accuracy: 0.2189\n",
      "Epoch 00004: saving model to model_init_2021-07-0516_22_40.984452/model-00004-1.72932-0.21891-1.36099-0.47000.h5\n",
      "67/67 [==============================] - 37s 553ms/step - loss: 1.7293 - categorical_accuracy: 0.2189 - val_loss: 1.3610 - val_categorical_accuracy: 0.4700\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6520 - categorical_accuracy: 0.2637\n",
      "Epoch 00005: saving model to model_init_2021-07-0516_22_40.984452/model-00005-1.65198-0.26368-1.45930-0.43000.h5\n",
      "67/67 [==============================] - 38s 566ms/step - loss: 1.6520 - categorical_accuracy: 0.2637 - val_loss: 1.4593 - val_categorical_accuracy: 0.4300\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5489 - categorical_accuracy: 0.2687\n",
      "Epoch 00006: saving model to model_init_2021-07-0516_22_40.984452/model-00006-1.54885-0.26866-1.31840-0.40000.h5\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 1.5489 - categorical_accuracy: 0.2687 - val_loss: 1.3184 - val_categorical_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5016 - categorical_accuracy: 0.3234\n",
      "Epoch 00007: saving model to model_init_2021-07-0516_22_40.984452/model-00007-1.50162-0.32338-1.27592-0.41000.h5\n",
      "67/67 [==============================] - 37s 551ms/step - loss: 1.5016 - categorical_accuracy: 0.3234 - val_loss: 1.2759 - val_categorical_accuracy: 0.4100\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4321 - categorical_accuracy: 0.3881\n",
      "Epoch 00008: saving model to model_init_2021-07-0516_22_40.984452/model-00008-1.43209-0.38806-1.26820-0.41000.h5\n",
      "67/67 [==============================] - 37s 548ms/step - loss: 1.4321 - categorical_accuracy: 0.3881 - val_loss: 1.2682 - val_categorical_accuracy: 0.4100\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5811 - categorical_accuracy: 0.2935\n",
      "Epoch 00009: saving model to model_init_2021-07-0516_22_40.984452/model-00009-1.58109-0.29353-1.36389-0.41000.h5\n",
      "67/67 [==============================] - 39s 581ms/step - loss: 1.5811 - categorical_accuracy: 0.2935 - val_loss: 1.3639 - val_categorical_accuracy: 0.4100\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4635 - categorical_accuracy: 0.3881\n",
      "Epoch 00010: saving model to model_init_2021-07-0516_22_40.984452/model-00010-1.46349-0.38806-1.30253-0.52000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 37s 547ms/step - loss: 1.4635 - categorical_accuracy: 0.3881 - val_loss: 1.3025 - val_categorical_accuracy: 0.5200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f54940e00f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 5 #left swipe, right swipe, thumbs up, thumbs down, stop\n",
    "channel = 3\n",
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height\n",
    "\n",
    "def generator_ex(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [x for x in range(0,x)] #create a list of image numbers you want to use for a particular video\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,channel)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,classes)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    temp = imresize(image,(y,z))\n",
    "                    #Converting to gray scale\n",
    "                    temp = temp.mean(axis=-1,keepdims=1) \n",
    "                    temp = temp/127.5-1 #Normalize data\n",
    "                    batch_data[folder,idx] = temp #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "                \n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            print(\"Batch: \",num_batches+1,\"Index:\", batch_size)\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            batch_data = np.zeros((batch_size,x,y,z,channel)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,classes)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    temp = imresize(image,(y,z))\n",
    "                    #Converting to gray scale\n",
    "                    temp = temp.mean(axis=-1,keepdims=1) \n",
    "                    temp = temp/127.5-1 #Normalize data\n",
    "                    \n",
    "                    batch_data[folder,idx] = temp\n",
    "                   \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'channel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c939f504f1b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define model b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'channel' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define model b\n",
    "model_b = Sequential()\n",
    "model_b.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,channel), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Dropout(0.25))\n",
    "\n",
    "model_b.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Dropout(0.25))\n",
    "\n",
    "model_b.add(Flatten())\n",
    "model_b.add(Dense(512, activation='relu'))\n",
    "model_b.add(Dropout(0.5))\n",
    "model_b.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model_b.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n",
      "65/67 [============================>.] - ETA: 2s - loss: 2.0070 - categorical_accuracy: 0.2046Batch:  67 Index: 10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9993 - categorical_accuracy: 0.2021Source path =  datasets/Project_data/val ; batch size = 10\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-1.99928-0.20211-1.60951-0.18000.h5\n",
      "67/67 [==============================] - 97s 1s/step - loss: 1.9993 - categorical_accuracy: 0.2021 - val_loss: 1.6095 - val_categorical_accuracy: 0.1800\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6104 - categorical_accuracy: 0.1692\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-1.61044-0.16915-1.60959-0.17000.h5\n",
      "67/67 [==============================] - 41s 605ms/step - loss: 1.6104 - categorical_accuracy: 0.1692 - val_loss: 1.6096 - val_categorical_accuracy: 0.1700\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6099 - categorical_accuracy: 0.2488\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-1.60986-0.24876-1.61020-0.20000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 42s 626ms/step - loss: 1.6099 - categorical_accuracy: 0.2488 - val_loss: 1.6102 - val_categorical_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6100 - categorical_accuracy: 0.1940\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-1.60998-0.19403-1.60917-0.20000.h5\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 1.6100 - categorical_accuracy: 0.1940 - val_loss: 1.6092 - val_categorical_accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6102 - categorical_accuracy: 0.1841\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-1.61021-0.18408-1.60874-0.17000.h5\n",
      "67/67 [==============================] - 41s 606ms/step - loss: 1.6102 - categorical_accuracy: 0.1841 - val_loss: 1.6087 - val_categorical_accuracy: 0.1700\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6102 - categorical_accuracy: 0.1841\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-1.61024-0.18408-1.60939-0.17000.h5\n",
      "67/67 [==============================] - 43s 638ms/step - loss: 1.6102 - categorical_accuracy: 0.1841 - val_loss: 1.6094 - val_categorical_accuracy: 0.1700\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6087 - categorical_accuracy: 0.2040\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-1.60868-0.20398-1.60699-0.20000.h5\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 1.6087 - categorical_accuracy: 0.2040 - val_loss: 1.6070 - val_categorical_accuracy: 0.2000\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6089 - categorical_accuracy: 0.2090\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-1.60891-0.20896-1.60860-0.18000.h5\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 1.6089 - categorical_accuracy: 0.2090 - val_loss: 1.6086 - val_categorical_accuracy: 0.1800\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6091 - categorical_accuracy: 0.1940\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-1.60908-0.19403-1.60848-0.19000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 42s 629ms/step - loss: 1.6091 - categorical_accuracy: 0.1940 - val_loss: 1.6085 - val_categorical_accuracy: 0.1900\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6095 - categorical_accuracy: 0.1891\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-1.60950-0.18905-1.61112-0.16000.h5\n",
      "67/67 [==============================] - 43s 642ms/step - loss: 1.6095 - categorical_accuracy: 0.1891 - val_loss: 1.6111 - val_categorical_accuracy: 0.1600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ee21bf5f8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing x,y,z values Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30 # number of frames\n",
    "y = 60 # image width\n",
    "z = 60 # image height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 30, 60, 60, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 30, 60, 60, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 10, 20, 20, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 10, 20, 20, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 6,621,925\n",
      "Trainable params: 6,621,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model b\n",
    "model_b = Sequential()\n",
    "model_b.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,channel), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Dropout(0.25))\n",
    "\n",
    "model_b.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Activation('relu'))\n",
    "model_b.add(MaxPooling3D(pool_size=(3, 3, 3), padding='same'))\n",
    "model_b.add(Dropout(0.25))\n",
    "\n",
    "model_b.add(Flatten())\n",
    "model_b.add(Dense(512, activation='relu'))\n",
    "model_b.add(Dropout(0.5))\n",
    "model_b.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model_b.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n",
      "65/67 [============================>.] - ETA: 2s - loss: 1.6375 - categorical_accuracy: 0.2046Batch:  67 Index: 10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6363 - categorical_accuracy: 0.2036Source path =  datasets/Project_data/val ; batch size = 10\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-1.63632-0.20362-1.55215-0.26000.h5\n",
      "67/67 [==============================] - 80s 1s/step - loss: 1.6363 - categorical_accuracy: 0.2036 - val_loss: 1.5521 - val_categorical_accuracy: 0.2600\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4989 - categorical_accuracy: 0.3284\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-1.49888-0.32836-1.43041-0.31000.h5\n",
      "67/67 [==============================] - 36s 530ms/step - loss: 1.4989 - categorical_accuracy: 0.3284 - val_loss: 1.4304 - val_categorical_accuracy: 0.3100\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4692 - categorical_accuracy: 0.2886\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-1.46918-0.28856-1.24701-0.41000.h5\n",
      "67/67 [==============================] - 34s 503ms/step - loss: 1.4692 - categorical_accuracy: 0.2886 - val_loss: 1.2470 - val_categorical_accuracy: 0.4100\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2995 - categorical_accuracy: 0.4378\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-1.29952-0.43781-1.12161-0.55000.h5\n",
      "67/67 [==============================] - 35s 525ms/step - loss: 1.2995 - categorical_accuracy: 0.4378 - val_loss: 1.1216 - val_categorical_accuracy: 0.5500\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2406 - categorical_accuracy: 0.4776\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-1.24064-0.47761-0.90769-0.65000.h5\n",
      "67/67 [==============================] - 36s 530ms/step - loss: 1.2406 - categorical_accuracy: 0.4776 - val_loss: 0.9077 - val_categorical_accuracy: 0.6500\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1257 - categorical_accuracy: 0.4925\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-1.12566-0.49254-0.96400-0.56000.h5\n",
      "67/67 [==============================] - 37s 550ms/step - loss: 1.1257 - categorical_accuracy: 0.4925 - val_loss: 0.9640 - val_categorical_accuracy: 0.5600\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9583 - categorical_accuracy: 0.6070\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-0.95834-0.60697-0.74260-0.71000.h5\n",
      "67/67 [==============================] - 37s 545ms/step - loss: 0.9583 - categorical_accuracy: 0.6070 - val_loss: 0.7426 - val_categorical_accuracy: 0.7100\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7892 - categorical_accuracy: 0.6965\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-0.78915-0.69652-0.91966-0.61000.h5\n",
      "67/67 [==============================] - 36s 538ms/step - loss: 0.7892 - categorical_accuracy: 0.6965 - val_loss: 0.9197 - val_categorical_accuracy: 0.6100\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8611 - categorical_accuracy: 0.6368\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-0.86110-0.63682-0.56399-0.73000.h5\n",
      "67/67 [==============================] - 36s 544ms/step - loss: 0.8611 - categorical_accuracy: 0.6368 - val_loss: 0.5640 - val_categorical_accuracy: 0.7300\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7373 - categorical_accuracy: 0.6965\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-0.73732-0.69652-0.71264-0.71000.h5\n",
      "67/67 [==============================] - 36s 532ms/step - loss: 0.7373 - categorical_accuracy: 0.6965 - val_loss: 0.7126 - val_categorical_accuracy: 0.7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ee1fd7a58>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Batch size to 20 Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, 20)\n",
    "val_generator = generator_ex(val_path, val_doc, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/10\n",
      "32/67 [=============>................] - ETA: 1:09 - loss: 0.5593 - categorical_accuracy: 0.7812Batch:  34 Index: 20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5708 - categorical_accuracy: 0.7808Source path =  datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-0.57080-0.78084-0.57051-0.77000.h5\n",
      "67/67 [==============================] - 105s 2s/step - loss: 0.5708 - categorical_accuracy: 0.7808 - val_loss: 0.5705 - val_categorical_accuracy: 0.7700\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5409 - categorical_accuracy: 0.8209\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-0.54092-0.82090-0.53144-0.82000.h5\n",
      "67/67 [==============================] - 49s 729ms/step - loss: 0.5409 - categorical_accuracy: 0.8209 - val_loss: 0.5314 - val_categorical_accuracy: 0.8200\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6485 - categorical_accuracy: 0.7164\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-0.64853-0.71642-0.47652-0.83500.h5\n",
      "67/67 [==============================] - 48s 718ms/step - loss: 0.6485 - categorical_accuracy: 0.7164 - val_loss: 0.4765 - val_categorical_accuracy: 0.8350\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6167 - categorical_accuracy: 0.7711\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-0.61665-0.77114-0.49669-0.85000.h5\n",
      "67/67 [==============================] - 48s 718ms/step - loss: 0.6167 - categorical_accuracy: 0.7711 - val_loss: 0.4967 - val_categorical_accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3993 - categorical_accuracy: 0.8706\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-0.39935-0.87065-0.57333-0.80000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 49s 732ms/step - loss: 0.3993 - categorical_accuracy: 0.8706 - val_loss: 0.5733 - val_categorical_accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5743 - categorical_accuracy: 0.8060\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-0.57432-0.80597-0.47332-0.85000.h5\n",
      "67/67 [==============================] - 48s 715ms/step - loss: 0.5743 - categorical_accuracy: 0.8060 - val_loss: 0.4733 - val_categorical_accuracy: 0.8500\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3298 - categorical_accuracy: 0.8806\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-0.32985-0.88060-0.43137-0.85500.h5\n",
      "67/67 [==============================] - 49s 729ms/step - loss: 0.3298 - categorical_accuracy: 0.8806 - val_loss: 0.4314 - val_categorical_accuracy: 0.8550\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4380 - categorical_accuracy: 0.8259\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-0.43803-0.82587-0.55875-0.85500.h5\n",
      "67/67 [==============================] - 47s 704ms/step - loss: 0.4380 - categorical_accuracy: 0.8259 - val_loss: 0.5588 - val_categorical_accuracy: 0.8550\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2906 - categorical_accuracy: 0.8806\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-0.29056-0.88060-0.40650-0.86000.h5\n",
      "67/67 [==============================] - 50s 744ms/step - loss: 0.2906 - categorical_accuracy: 0.8806 - val_loss: 0.4065 - val_categorical_accuracy: 0.8600\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3016 - categorical_accuracy: 0.8905\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-0.30159-0.89055-0.42415-0.89000.h5\n",
      "67/67 [==============================] - 49s 733ms/step - loss: 0.3016 - categorical_accuracy: 0.8905 - val_loss: 0.4242 - val_categorical_accuracy: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ee21c0c88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Batch size to 30 Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, 30)\n",
    "val_generator = generator_ex(val_path, val_doc, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 30\n",
      "Epoch 1/10\n",
      "21/67 [========>.....................] - ETA: 2:13 - loss: 0.1926 - categorical_accuracy: 0.9206Batch:  23 Index: 30\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1854 - categorical_accuracy: 0.9258Source path =  datasets/Project_data/val ; batch size = 30\n",
      "Batch:  4 Index: 30\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-0.18541-0.92579-0.42341-0.85625.h5\n",
      "67/67 [==============================] - 101s 2s/step - loss: 0.1854 - categorical_accuracy: 0.9258 - val_loss: 0.4234 - val_categorical_accuracy: 0.8562\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3255 - categorical_accuracy: 0.8756\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-0.32550-0.87562-0.45815-0.83000.h5\n",
      "67/67 [==============================] - 36s 535ms/step - loss: 0.3255 - categorical_accuracy: 0.8756 - val_loss: 0.4582 - val_categorical_accuracy: 0.8300\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2604 - categorical_accuracy: 0.8706\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-0.26043-0.87065-0.44868-0.84000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 36s 535ms/step - loss: 0.2604 - categorical_accuracy: 0.8706 - val_loss: 0.4487 - val_categorical_accuracy: 0.8400\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2583 - categorical_accuracy: 0.9154\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-0.25826-0.91542-0.29535-0.89000.h5\n",
      "67/67 [==============================] - 33s 494ms/step - loss: 0.2583 - categorical_accuracy: 0.9154 - val_loss: 0.2953 - val_categorical_accuracy: 0.8900\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1549 - categorical_accuracy: 0.9254\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-0.15487-0.92537-0.42260-0.88000.h5\n",
      "67/67 [==============================] - 33s 490ms/step - loss: 0.1549 - categorical_accuracy: 0.9254 - val_loss: 0.4226 - val_categorical_accuracy: 0.8800\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1743 - categorical_accuracy: 0.9303\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-0.17426-0.93035-0.48297-0.86000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 34s 512ms/step - loss: 0.1743 - categorical_accuracy: 0.9303 - val_loss: 0.4830 - val_categorical_accuracy: 0.8600\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1122 - categorical_accuracy: 0.9602\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-0.11218-0.96020-0.45953-0.86000.h5\n",
      "67/67 [==============================] - 34s 500ms/step - loss: 0.1122 - categorical_accuracy: 0.9602 - val_loss: 0.4595 - val_categorical_accuracy: 0.8600\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0837 - categorical_accuracy: 0.9751\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-0.08372-0.97512-0.33208-0.89000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 32s 481ms/step - loss: 0.0837 - categorical_accuracy: 0.9751 - val_loss: 0.3321 - val_categorical_accuracy: 0.8900\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0912 - categorical_accuracy: 0.9751\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-0.09118-0.97512-0.32373-0.89000.h5\n",
      "67/67 [==============================] - 36s 542ms/step - loss: 0.0912 - categorical_accuracy: 0.9751 - val_loss: 0.3237 - val_categorical_accuracy: 0.8900\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1037 - categorical_accuracy: 0.9652\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-0.10365-0.96517-0.45209-0.80000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "67/67 [==============================] - 33s 491ms/step - loss: 0.1037 - categorical_accuracy: 0.9652 - val_loss: 0.4521 - val_categorical_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ee15a9358>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Batch size to 40 Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, 40)\n",
    "val_generator = generator_ex(val_path, val_doc, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 40\n",
      "Epoch 1/10\n",
      "15/67 [=====>........................] - ETA: 3:03 - loss: 0.1013 - categorical_accuracy: 0.9733Batch:  17 Index: 40\n",
      "44/67 [==================>...........] - ETA: 1:02 - loss: 0.0863 - categorical_accuracy: 0.9774Batch:  29 Index: 23\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0859 - categorical_accuracy: 0.9762Source path =  datasets/Project_data/val ; batch size = 40\n",
      "Batch:  3 Index: 40\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-0.08594-0.97623-0.41888-0.84583.h5\n",
      "67/67 [==============================] - 190s 3s/step - loss: 0.0859 - categorical_accuracy: 0.9762 - val_loss: 0.4189 - val_categorical_accuracy: 0.8458\n",
      "Epoch 2/10\n",
      "12/67 [====>.........................] - ETA: 1:43 - loss: 0.0994 - categorical_accuracy: 0.9693Batch:  35 Index: 19\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0756 - categorical_accuracy: 0.9777\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-0.07558-0.97768-0.41364-0.87500.h5\n",
      "67/67 [==============================] - 147s 2s/step - loss: 0.0756 - categorical_accuracy: 0.9777 - val_loss: 0.4136 - val_categorical_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0871 - categorical_accuracy: 0.9684\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-0.08707-0.96839-0.36378-0.88500.h5\n",
      "67/67 [==============================] - 141s 2s/step - loss: 0.0871 - categorical_accuracy: 0.9684 - val_loss: 0.3638 - val_categorical_accuracy: 0.8850\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0707 - categorical_accuracy: 0.9719\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-0.07068-0.97191-0.39113-0.88000.h5\n",
      "67/67 [==============================] - 145s 2s/step - loss: 0.0707 - categorical_accuracy: 0.9719 - val_loss: 0.3911 - val_categorical_accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0807 - categorical_accuracy: 0.9754\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-0.08068-0.97542-0.34925-0.88500.h5\n",
      "67/67 [==============================] - 143s 2s/step - loss: 0.0807 - categorical_accuracy: 0.9754 - val_loss: 0.3493 - val_categorical_accuracy: 0.8850\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0691 - categorical_accuracy: 0.9824\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-0.06905-0.98244-0.38419-0.87000.h5\n",
      "67/67 [==============================] - 142s 2s/step - loss: 0.0691 - categorical_accuracy: 0.9824 - val_loss: 0.3842 - val_categorical_accuracy: 0.8700\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0670 - categorical_accuracy: 0.9789\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-0.06705-0.97893-0.38549-0.87000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "67/67 [==============================] - 145s 2s/step - loss: 0.0670 - categorical_accuracy: 0.9789 - val_loss: 0.3855 - val_categorical_accuracy: 0.8700\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0643 - categorical_accuracy: 0.9842\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-0.06426-0.98420-0.38220-0.88500.h5\n",
      "67/67 [==============================] - 139s 2s/step - loss: 0.0643 - categorical_accuracy: 0.9842 - val_loss: 0.3822 - val_categorical_accuracy: 0.8850\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0724 - categorical_accuracy: 0.9781\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-0.07240-0.97805-0.39414-0.87000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "67/67 [==============================] - 131s 2s/step - loss: 0.0724 - categorical_accuracy: 0.9781 - val_loss: 0.3941 - val_categorical_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0785 - categorical_accuracy: 0.9701\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-0.07854-0.97015-0.41813-0.86000.h5\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0785 - categorical_accuracy: 0.9701 - val_loss: 0.4181 - val_categorical_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ee1502518>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Optimizer to Adadelta Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 30, 60, 60, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 30, 60, 60, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 10, 20, 20, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 10, 20, 20, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 6,621,925\n",
      "Trainable params: 6,621,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_b.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, 40)\n",
    "val_generator = generator_ex(val_path, val_doc, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 40\n",
      "Epoch 1/10\n",
      "15/67 [=====>........................] - ETA: 3:01 - loss: 0.0733 - categorical_accuracy: 0.9783Batch:  17 Index: 40\n",
      "44/67 [==================>...........] - ETA: 1:02 - loss: 0.0631 - categorical_accuracy: 0.9821Batch:  29 Index: 23\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0662 - categorical_accuracy: 0.9809Source path =  datasets/Project_data/val ; batch size = 40\n",
      "Batch:  3 Index: 40\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-0.06622-0.98087-0.44037-0.86667.h5\n",
      "67/67 [==============================] - 191s 3s/step - loss: 0.0662 - categorical_accuracy: 0.9809 - val_loss: 0.4404 - val_categorical_accuracy: 0.8667\n",
      "Epoch 2/10\n",
      "12/67 [====>.........................] - ETA: 1:29 - loss: 0.0573 - categorical_accuracy: 0.9825Batch:  35 Index: 19\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0697 - categorical_accuracy: 0.9751\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-0.06972-0.97511-0.40241-0.86500.h5\n",
      "67/67 [==============================] - 134s 2s/step - loss: 0.0697 - categorical_accuracy: 0.9751 - val_loss: 0.4024 - val_categorical_accuracy: 0.8650\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0640 - categorical_accuracy: 0.9798\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-0.06401-0.97981-0.46632-0.85000.h5\n",
      "67/67 [==============================] - 134s 2s/step - loss: 0.0640 - categorical_accuracy: 0.9798 - val_loss: 0.4663 - val_categorical_accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0672 - categorical_accuracy: 0.9789\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-0.06718-0.97893-0.39496-0.87000.h5\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0672 - categorical_accuracy: 0.9789 - val_loss: 0.3950 - val_categorical_accuracy: 0.8700\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0773 - categorical_accuracy: 0.9737\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-0.07730-0.97366-0.38531-0.87500.h5\n",
      "67/67 [==============================] - 135s 2s/step - loss: 0.0773 - categorical_accuracy: 0.9737 - val_loss: 0.3853 - val_categorical_accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0650 - categorical_accuracy: 0.9781\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-0.06501-0.97805-0.37794-0.87500.h5\n",
      "67/67 [==============================] - 131s 2s/step - loss: 0.0650 - categorical_accuracy: 0.9781 - val_loss: 0.3779 - val_categorical_accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0673 - categorical_accuracy: 0.9789\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-0.06726-0.97893-0.34246-0.88000.h5\n",
      "67/67 [==============================] - 132s 2s/step - loss: 0.0673 - categorical_accuracy: 0.9789 - val_loss: 0.3425 - val_categorical_accuracy: 0.8800\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0575 - categorical_accuracy: 0.9842\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-0.05753-0.98420-0.46075-0.85000.h5\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0575 - categorical_accuracy: 0.9842 - val_loss: 0.4608 - val_categorical_accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0682 - categorical_accuracy: 0.9798\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-0.06823-0.97981-0.39536-0.87000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 131s 2s/step - loss: 0.0682 - categorical_accuracy: 0.9798 - val_loss: 0.3954 - val_categorical_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0670 - categorical_accuracy: 0.9763\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-0.06701-0.97629-0.45145-0.85000.h5\n",
      "67/67 [==============================] - 134s 2s/step - loss: 0.0670 - categorical_accuracy: 0.9763 - val_loss: 0.4515 - val_categorical_accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ee16dc5f8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change epoch to 20 Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model_b.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = generator_ex(train_path, train_doc, 40)\n",
    "val_generator = generator_ex(val_path, val_doc, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 40\n",
      "Epoch 1/20\n",
      "15/67 [=====>........................] - ETA: 3:07 - loss: 0.0559 - categorical_accuracy: 0.9850Batch:  17 Index: 40\n",
      "44/67 [==================>...........] - ETA: 1:02 - loss: 0.0644 - categorical_accuracy: 0.9829Batch:  29 Index: 23\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0638 - categorical_accuracy: 0.9826Source path =  datasets/Project_data/val ; batch size = 40\n",
      "Batch:  3 Index: 40\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-0.06377-0.98261-0.43489-0.86250.h5\n",
      "67/67 [==============================] - 194s 3s/step - loss: 0.0638 - categorical_accuracy: 0.9826 - val_loss: 0.4349 - val_categorical_accuracy: 0.8625\n",
      "Epoch 2/20\n",
      "12/67 [====>.........................] - ETA: 1:28 - loss: 0.0663 - categorical_accuracy: 0.9781Batch:  35 Index: 19\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0620 - categorical_accuracy: 0.9811\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-0.06203-0.98112-0.41550-0.86500.h5\n",
      "67/67 [==============================] - 134s 2s/step - loss: 0.0620 - categorical_accuracy: 0.9811 - val_loss: 0.4155 - val_categorical_accuracy: 0.8650\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0688 - categorical_accuracy: 0.9807\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-0.06877-0.98068-0.40210-0.86500.h5\n",
      "67/67 [==============================] - 131s 2s/step - loss: 0.0688 - categorical_accuracy: 0.9807 - val_loss: 0.4021 - val_categorical_accuracy: 0.8650\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0643 - categorical_accuracy: 0.9824\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-0.06434-0.98244-0.39596-0.87000.h5\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0643 - categorical_accuracy: 0.9824 - val_loss: 0.3960 - val_categorical_accuracy: 0.8700\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0803 - categorical_accuracy: 0.9719\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-0.08032-0.97191-0.40790-0.87000.h5\n",
      "67/67 [==============================] - 134s 2s/step - loss: 0.0803 - categorical_accuracy: 0.9719 - val_loss: 0.4079 - val_categorical_accuracy: 0.8700\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0697 - categorical_accuracy: 0.9745\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-0.06972-0.97454-0.36596-0.87500.h5\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0697 - categorical_accuracy: 0.9745 - val_loss: 0.3660 - val_categorical_accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0661 - categorical_accuracy: 0.9798\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-0.06611-0.97981-0.42042-0.86000.h5\n",
      "67/67 [==============================] - 132s 2s/step - loss: 0.0661 - categorical_accuracy: 0.9798 - val_loss: 0.4204 - val_categorical_accuracy: 0.8600\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0619 - categorical_accuracy: 0.9842\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-0.06190-0.98420-0.39269-0.87000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 134s 2s/step - loss: 0.0619 - categorical_accuracy: 0.9842 - val_loss: 0.3927 - val_categorical_accuracy: 0.8700\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0680 - categorical_accuracy: 0.9763\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-0.06798-0.97629-0.39650-0.87000.h5\n",
      "67/67 [==============================] - 132s 2s/step - loss: 0.0680 - categorical_accuracy: 0.9763 - val_loss: 0.3965 - val_categorical_accuracy: 0.8700\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0694 - categorical_accuracy: 0.9754\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-0.06938-0.97542-0.43089-0.86000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0694 - categorical_accuracy: 0.9754 - val_loss: 0.4309 - val_categorical_accuracy: 0.8600\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0608 - categorical_accuracy: 0.9745\n",
      "Epoch 00011: saving model to model_init_2021-07-0511_47_52.386877/model-00011-0.06083-0.97454-0.40595-0.86500.h5\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0608 - categorical_accuracy: 0.9745 - val_loss: 0.4060 - val_categorical_accuracy: 0.8650\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0528 - categorical_accuracy: 0.9842\n",
      "Epoch 00012: saving model to model_init_2021-07-0511_47_52.386877/model-00012-0.05282-0.98420-0.40101-0.86500.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 134s 2s/step - loss: 0.0528 - categorical_accuracy: 0.9842 - val_loss: 0.4010 - val_categorical_accuracy: 0.8650\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0660 - categorical_accuracy: 0.9763\n",
      "Epoch 00013: saving model to model_init_2021-07-0511_47_52.386877/model-00013-0.06601-0.97629-0.37427-0.88000.h5\n",
      "67/67 [==============================] - 132s 2s/step - loss: 0.0660 - categorical_accuracy: 0.9763 - val_loss: 0.3743 - val_categorical_accuracy: 0.8800\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0634 - categorical_accuracy: 0.9789\n",
      "Epoch 00014: saving model to model_init_2021-07-0511_47_52.386877/model-00014-0.06344-0.97893-0.39647-0.87000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0634 - categorical_accuracy: 0.9789 - val_loss: 0.3965 - val_categorical_accuracy: 0.8700\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0558 - categorical_accuracy: 0.9860\n",
      "Epoch 00015: saving model to model_init_2021-07-0511_47_52.386877/model-00015-0.05580-0.98595-0.37257-0.88500.h5\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0558 - categorical_accuracy: 0.9860 - val_loss: 0.3726 - val_categorical_accuracy: 0.8850\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0671 - categorical_accuracy: 0.9789\n",
      "Epoch 00016: saving model to model_init_2021-07-0511_47_52.386877/model-00016-0.06707-0.97893-0.38485-0.87000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0671 - categorical_accuracy: 0.9789 - val_loss: 0.3849 - val_categorical_accuracy: 0.8700\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0625 - categorical_accuracy: 0.9816\n",
      "Epoch 00017: saving model to model_init_2021-07-0511_47_52.386877/model-00017-0.06250-0.98156-0.42260-0.86000.h5\n",
      "67/67 [==============================] - 131s 2s/step - loss: 0.0625 - categorical_accuracy: 0.9816 - val_loss: 0.4226 - val_categorical_accuracy: 0.8600\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0679 - categorical_accuracy: 0.9816\n",
      "Epoch 00018: saving model to model_init_2021-07-0511_47_52.386877/model-00018-0.06790-0.98156-0.37633-0.87500.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0679 - categorical_accuracy: 0.9816 - val_loss: 0.3763 - val_categorical_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0617 - categorical_accuracy: 0.9789\n",
      "Epoch 00019: saving model to model_init_2021-07-0511_47_52.386877/model-00019-0.06169-0.97893-0.39650-0.87000.h5\n",
      "67/67 [==============================] - 132s 2s/step - loss: 0.0617 - categorical_accuracy: 0.9789 - val_loss: 0.3965 - val_categorical_accuracy: 0.8700\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0668 - categorical_accuracy: 0.9781\n",
      "Epoch 00020: saving model to model_init_2021-07-0511_47_52.386877/model-00020-0.06680-0.97805-0.40955-0.86500.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "67/67 [==============================] - 133s 2s/step - loss: 0.0668 - categorical_accuracy: 0.9781 - val_loss: 0.4095 - val_categorical_accuracy: 0.8650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ee1445c88>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_b.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model C Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_12 (Conv3D)           (None, 30, 60, 60, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 30, 60, 60, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 20, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 10, 20, 20, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 10, 20, 20, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10, 20, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 4, 7, 7, 64)       110656    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 4, 7, 7, 64)       110656    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 2, 3, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2, 3, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 1,012,581\n",
      "Trainable params: 1,011,557\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_c = Sequential()\n",
    "model_c.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,channel), padding=\"same\"))\n",
    "model_c.add(Activation('relu'))\n",
    "model_c.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_c.add(Activation('relu'))\n",
    "model_c.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_c.add(Dropout(0.25))\n",
    "\n",
    "model_c.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_c.add(Activation('relu'))\n",
    "model_c.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_c.add(Activation('relu'))\n",
    "model_c.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_c.add(Dropout(0.25))\n",
    "\n",
    "model_c.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_c.add(Activation('relu'))\n",
    "model_c.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_c.add(Activation('relu'))\n",
    "model_c.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_c.add(Dropout(0.25))\n",
    "\n",
    "model_c.add(Flatten())\n",
    "model_c.add(Dense(512, activation='relu'))\n",
    "model_c.add(BatchNormalization())\n",
    "model_c.add(Dropout(0.5))\n",
    "model_c.add(Dense(classes, activation='softmax'))\n",
    "model_c.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing back batch size, images per frame, height and width of image\n",
    "batch_size = 10\n",
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120# image height\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Input to reshape is a tensor with 32000 values, but the requested shape requires a multiple of 1152\n\t [[node sequential_3/flatten_3/Reshape (defined at <ipython-input-37-31a23c77d6f4>:3) ]] [Op:__inference_train_function_31852]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-31a23c77d6f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_c.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n\u001b[1;32m      2\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 32000 values, but the requested shape requires a multiple of 1152\n\t [[node sequential_3/flatten_3/Reshape (defined at <ipython-input-37-31a23c77d6f4>:3) ]] [Op:__inference_train_function_31852]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model_c.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model D Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_4 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,749\n",
      "Trainable params: 3,667,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(x,y,z,channel)\n",
    "\n",
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [1000, 500, 5]\n",
    "# Define model\n",
    "model_d = Sequential()\n",
    "\n",
    "model_d.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_d.add(BatchNormalization())\n",
    "model_d.add(Activation('relu'))\n",
    "\n",
    "model_d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_d.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_d.add(BatchNormalization())\n",
    "model_d.add(Activation('relu'))\n",
    "\n",
    "model_d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_d.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_d.add(BatchNormalization())\n",
    "model_d.add(Activation('relu'))\n",
    "\n",
    "model_d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_d.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_d.add(BatchNormalization())\n",
    "model_d.add(Activation('relu'))\n",
    "\n",
    "model_d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_d.add(Flatten())\n",
    "\n",
    "model_d.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_d.add(Dropout(0.5))\n",
    "\n",
    "model_d.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_d.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_d.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_d.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_d.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n",
      "65/67 [============================>.] - ETA: 2s - loss: 2.9327 - categorical_accuracy: 0.2231Batch:  67 Index: 10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.9367 - categorical_accuracy: 0.2217Source path =  datasets/Project_data/val ; batch size = 10\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-2.93669-0.22172-1.60484-0.24000.h5\n",
      "67/67 [==============================] - 91s 1s/step - loss: 2.9367 - categorical_accuracy: 0.2217 - val_loss: 1.6048 - val_categorical_accuracy: 0.2400\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.5916 - categorical_accuracy: 0.2637\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-2.59165-0.26368-1.61963-0.17000.h5\n",
      "67/67 [==============================] - 39s 582ms/step - loss: 2.5916 - categorical_accuracy: 0.2637 - val_loss: 1.6196 - val_categorical_accuracy: 0.1700\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6942 - categorical_accuracy: 0.2189\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-2.69423-0.21891-1.63117-0.18000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 38s 568ms/step - loss: 2.6942 - categorical_accuracy: 0.2189 - val_loss: 1.6312 - val_categorical_accuracy: 0.1800\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.9537 - categorical_accuracy: 0.2189\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-2.95373-0.21891-1.63481-0.26000.h5\n",
      "67/67 [==============================] - 36s 544ms/step - loss: 2.9537 - categorical_accuracy: 0.2189 - val_loss: 1.6348 - val_categorical_accuracy: 0.2600\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.4965 - categorical_accuracy: 0.2388\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-2.49654-0.23881-1.66958-0.22000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 37s 553ms/step - loss: 2.4965 - categorical_accuracy: 0.2388 - val_loss: 1.6696 - val_categorical_accuracy: 0.2200\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.8518 - categorical_accuracy: 0.1791\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-2.85183-0.17910-1.58115-0.37000.h5\n",
      "67/67 [==============================] - 39s 577ms/step - loss: 2.8518 - categorical_accuracy: 0.1791 - val_loss: 1.5812 - val_categorical_accuracy: 0.3700\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.9256 - categorical_accuracy: 0.1791\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-2.92560-0.17910-1.66627-0.27000.h5\n",
      "67/67 [==============================] - 38s 563ms/step - loss: 2.9256 - categorical_accuracy: 0.1791 - val_loss: 1.6663 - val_categorical_accuracy: 0.2700\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6632 - categorical_accuracy: 0.1891\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-2.66319-0.18905-1.64414-0.34000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 38s 562ms/step - loss: 2.6632 - categorical_accuracy: 0.1891 - val_loss: 1.6441 - val_categorical_accuracy: 0.3400\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6188 - categorical_accuracy: 0.2438\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-2.61877-0.24378-1.66634-0.25000.h5\n",
      "67/67 [==============================] - 38s 565ms/step - loss: 2.6188 - categorical_accuracy: 0.2438 - val_loss: 1.6663 - val_categorical_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.7352 - categorical_accuracy: 0.1343\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-2.73524-0.13433-1.71419-0.22000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 38s 569ms/step - loss: 2.7352 - categorical_accuracy: 0.1343 - val_loss: 1.7142 - val_categorical_accuracy: 0.2200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ee22259b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 10\n",
    "model_d.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Model with images per frame, width and height of the images Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = 30 # number of frames\n",
    "y = 64 # image width\n",
    "z = 64 # image height \n",
    "\n",
    "classes = 5\n",
    "channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 30, 64, 64, 32)    896       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 30, 64, 64, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 30, 64, 64, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 10, 22, 22, 32)    0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 22, 22, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 10, 22, 22, 64)    55360     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10, 22, 22, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 10, 22, 22, 64)    110656    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 22, 22, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 4, 8, 8, 64)       110656    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 4, 8, 8, 64)       110656    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4, 8, 8, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 2, 3, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 3, 3, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 1,010,853\n",
      "Trainable params: 1,009,829\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_e = Sequential()\n",
    "model_e.add(Conv3D(32, kernel_size=(3, 3, 3), input_shape=(x,y,z,channel), padding=\"same\"))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_e.add(Dropout(0.25))\n",
    "\n",
    "model_e.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_e.add(Dropout(0.25))\n",
    "\n",
    "model_e.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(Conv3D(64, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "model_e.add(Activation('relu'))\n",
    "model_e.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "model_e.add(Dropout(0.25))\n",
    "\n",
    "model_e.add(Flatten())\n",
    "model_e.add(Dense(512, activation='relu'))\n",
    "model_e.add(BatchNormalization())\n",
    "model_e.add(Dropout(0.5))\n",
    "model_e.add(Dense(classes, activation='softmax'))\n",
    "model_e.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 5\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9819 - categorical_accuracy: 0.1672Source path =  datasets/Project_data/val ; batch size = 5\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-1.98186-0.16716-1.61269-0.16000.h5\n",
      "67/67 [==============================] - 39s 580ms/step - loss: 1.9819 - categorical_accuracy: 0.1672 - val_loss: 1.6127 - val_categorical_accuracy: 0.1600\n",
      "Epoch 2/20\n",
      "64/67 [===========================>..] - ETA: 1s - loss: 1.9745 - categorical_accuracy: 0.1937Batch:  133 Index: 5\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9845 - categorical_accuracy: 0.1903\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-1.98450-0.19033-1.61574-0.20000.h5\n",
      "67/67 [==============================] - 39s 583ms/step - loss: 1.9845 - categorical_accuracy: 0.1903 - val_loss: 1.6157 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9650 - categorical_accuracy: 0.1791\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-1.96501-0.17910-1.61297-0.22000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 27s 405ms/step - loss: 1.9650 - categorical_accuracy: 0.1791 - val_loss: 1.6130 - val_categorical_accuracy: 0.2200\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9087 - categorical_accuracy: 0.2139\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-1.90866-0.21393-1.60261-0.24000.h5\n",
      "67/67 [==============================] - 28s 416ms/step - loss: 1.9087 - categorical_accuracy: 0.2139 - val_loss: 1.6026 - val_categorical_accuracy: 0.2400\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9819 - categorical_accuracy: 0.1642\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-1.98192-0.16418-1.61418-0.30000.h5\n",
      "67/67 [==============================] - 27s 397ms/step - loss: 1.9819 - categorical_accuracy: 0.1642 - val_loss: 1.6142 - val_categorical_accuracy: 0.3000\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9899 - categorical_accuracy: 0.1940\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-1.98989-0.19403-1.65221-0.24000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 27s 404ms/step - loss: 1.9899 - categorical_accuracy: 0.1940 - val_loss: 1.6522 - val_categorical_accuracy: 0.2400\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9267 - categorical_accuracy: 0.1692\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-1.92671-0.16915-1.66406-0.22000.h5\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 1.9267 - categorical_accuracy: 0.1692 - val_loss: 1.6641 - val_categorical_accuracy: 0.2200\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.8474 - categorical_accuracy: 0.2338\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-1.84739-0.23383-1.77523-0.14000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 27s 399ms/step - loss: 1.8474 - categorical_accuracy: 0.2338 - val_loss: 1.7752 - val_categorical_accuracy: 0.1400\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9028 - categorical_accuracy: 0.1741\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-1.90282-0.17413-1.71104-0.26000.h5\n",
      "67/67 [==============================] - 27s 409ms/step - loss: 1.9028 - categorical_accuracy: 0.1741 - val_loss: 1.7110 - val_categorical_accuracy: 0.2600\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9964 - categorical_accuracy: 0.1990\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-1.99638-0.19900-1.79453-0.22000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 27s 406ms/step - loss: 1.9964 - categorical_accuracy: 0.1990 - val_loss: 1.7945 - val_categorical_accuracy: 0.2200\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.0281 - categorical_accuracy: 0.1542\n",
      "Epoch 00011: saving model to model_init_2021-07-0511_47_52.386877/model-00011-2.02810-0.15423-1.76894-0.24000.h5\n",
      "67/67 [==============================] - 28s 415ms/step - loss: 2.0281 - categorical_accuracy: 0.1542 - val_loss: 1.7689 - val_categorical_accuracy: 0.2400\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.8705 - categorical_accuracy: 0.1940\n",
      "Epoch 00012: saving model to model_init_2021-07-0511_47_52.386877/model-00012-1.87047-0.19403-1.87497-0.20000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 1.8705 - categorical_accuracy: 0.1940 - val_loss: 1.8750 - val_categorical_accuracy: 0.2000\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.0448 - categorical_accuracy: 0.1741\n",
      "Epoch 00013: saving model to model_init_2021-07-0511_47_52.386877/model-00013-2.04482-0.17413-1.90538-0.20000.h5\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 2.0448 - categorical_accuracy: 0.1741 - val_loss: 1.9054 - val_categorical_accuracy: 0.2000\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9128 - categorical_accuracy: 0.1891\n",
      "Epoch 00014: saving model to model_init_2021-07-0511_47_52.386877/model-00014-1.91276-0.18905-1.78337-0.28000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "67/67 [==============================] - 27s 396ms/step - loss: 1.9128 - categorical_accuracy: 0.1891 - val_loss: 1.7834 - val_categorical_accuracy: 0.2800\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.8546 - categorical_accuracy: 0.1741\n",
      "Epoch 00015: saving model to model_init_2021-07-0511_47_52.386877/model-00015-1.85459-0.17413-1.81598-0.28000.h5\n",
      "67/67 [==============================] - 28s 412ms/step - loss: 1.8546 - categorical_accuracy: 0.1741 - val_loss: 1.8160 - val_categorical_accuracy: 0.2800\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9274 - categorical_accuracy: 0.1692\n",
      "Epoch 00016: saving model to model_init_2021-07-0511_47_52.386877/model-00016-1.92735-0.16915-1.88702-0.22000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "67/67 [==============================] - 26s 388ms/step - loss: 1.9274 - categorical_accuracy: 0.1692 - val_loss: 1.8870 - val_categorical_accuracy: 0.2200\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9993 - categorical_accuracy: 0.1393\n",
      "Epoch 00017: saving model to model_init_2021-07-0511_47_52.386877/model-00017-1.99927-0.13930-1.91752-0.22000.h5\n",
      "67/67 [==============================] - 27s 410ms/step - loss: 1.9993 - categorical_accuracy: 0.1393 - val_loss: 1.9175 - val_categorical_accuracy: 0.2200\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9922 - categorical_accuracy: 0.1642\n",
      "Epoch 00018: saving model to model_init_2021-07-0511_47_52.386877/model-00018-1.99218-0.16418-1.76124-0.30000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "67/67 [==============================] - 29s 433ms/step - loss: 1.9922 - categorical_accuracy: 0.1642 - val_loss: 1.7612 - val_categorical_accuracy: 0.3000\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9190 - categorical_accuracy: 0.1642\n",
      "Epoch 00019: saving model to model_init_2021-07-0511_47_52.386877/model-00019-1.91897-0.16418-1.84670-0.20000.h5\n",
      "67/67 [==============================] - 25s 380ms/step - loss: 1.9190 - categorical_accuracy: 0.1642 - val_loss: 1.8467 - val_categorical_accuracy: 0.2000\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9695 - categorical_accuracy: 0.1592\n",
      "Epoch 00020: saving model to model_init_2021-07-0511_47_52.386877/model-00020-1.96950-0.15920-1.85212-0.24000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "67/67 [==============================] - 28s 420ms/step - loss: 1.9695 - categorical_accuracy: 0.1592 - val_loss: 1.8521 - val_categorical_accuracy: 0.2400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0e55dcac18>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 20\n",
    "model_e.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model F Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_14 (Conv3D)           (None, 30, 120, 120, 8)   224       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,317\n",
      "Trainable params: 3,667,077\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "classes = 5\n",
    "channel = 1\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "input_shape=(x,y,z,channel)\n",
    "\n",
    "# Define model\n",
    "model_f = Sequential()\n",
    "\n",
    "model_f.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_f.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_f.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_f.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_f.add(BatchNormalization())\n",
    "model_f.add(Activation('relu'))\n",
    "\n",
    "model_f.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_f.add(Flatten())\n",
    "\n",
    "model_f.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_f.add(Dropout(0.5))\n",
    "\n",
    "model_f.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_f.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_f.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_f.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_f.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 10\n",
      "Epoch 1/20\n",
      "65/67 [============================>.] - ETA: 2s - loss: 2.9666 - categorical_accuracy: 0.2292Batch:  67 Index: 10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.9727 - categorical_accuracy: 0.2262Source path =  datasets/Project_data/val ; batch size = 10\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-2.97274-0.22624-1.62609-0.17000.h5\n",
      "67/67 [==============================] - 83s 1s/step - loss: 2.9727 - categorical_accuracy: 0.2262 - val_loss: 1.6261 - val_categorical_accuracy: 0.1700\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.8852 - categorical_accuracy: 0.2338\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-2.88525-0.23383-1.64439-0.20000.h5\n",
      "67/67 [==============================] - 38s 568ms/step - loss: 2.8852 - categorical_accuracy: 0.2338 - val_loss: 1.6444 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.8538 - categorical_accuracy: 0.2488\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-2.85378-0.24876-1.61604-0.26000.h5\n",
      "67/67 [==============================] - 36s 536ms/step - loss: 2.8538 - categorical_accuracy: 0.2488 - val_loss: 1.6160 - val_categorical_accuracy: 0.2600\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.7891 - categorical_accuracy: 0.2090\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-2.78910-0.20896-1.60481-0.18000.h5\n",
      "67/67 [==============================] - 34s 509ms/step - loss: 2.7891 - categorical_accuracy: 0.2090 - val_loss: 1.6048 - val_categorical_accuracy: 0.1800\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.5549 - categorical_accuracy: 0.2537\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-2.55493-0.25373-1.58143-0.21000.h5\n",
      "67/67 [==============================] - 36s 533ms/step - loss: 2.5549 - categorical_accuracy: 0.2537 - val_loss: 1.5814 - val_categorical_accuracy: 0.2100\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.4912 - categorical_accuracy: 0.2338\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-2.49120-0.23383-1.58988-0.22000.h5\n",
      "67/67 [==============================] - 36s 539ms/step - loss: 2.4912 - categorical_accuracy: 0.2338 - val_loss: 1.5899 - val_categorical_accuracy: 0.2200\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.1847 - categorical_accuracy: 0.1692\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-3.18470-0.16915-1.54789-0.21000.h5\n",
      "67/67 [==============================] - 36s 545ms/step - loss: 3.1847 - categorical_accuracy: 0.1692 - val_loss: 1.5479 - val_categorical_accuracy: 0.2100\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.7917 - categorical_accuracy: 0.2040\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-2.79165-0.20398-1.55002-0.27000.h5\n",
      "67/67 [==============================] - 36s 540ms/step - loss: 2.7917 - categorical_accuracy: 0.2040 - val_loss: 1.5500 - val_categorical_accuracy: 0.2700\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.0062 - categorical_accuracy: 0.1692\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-3.00623-0.16915-1.57179-0.23000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 36s 537ms/step - loss: 3.0062 - categorical_accuracy: 0.1692 - val_loss: 1.5718 - val_categorical_accuracy: 0.2300\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.7471 - categorical_accuracy: 0.2189\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-2.74712-0.21891-1.56181-0.21000.h5\n",
      "67/67 [==============================] - 37s 546ms/step - loss: 2.7471 - categorical_accuracy: 0.2189 - val_loss: 1.5618 - val_categorical_accuracy: 0.2100\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.5313 - categorical_accuracy: 0.2587\n",
      "Epoch 00011: saving model to model_init_2021-07-0511_47_52.386877/model-00011-2.53127-0.25871-1.55884-0.27000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 36s 533ms/step - loss: 2.5313 - categorical_accuracy: 0.2587 - val_loss: 1.5588 - val_categorical_accuracy: 0.2700\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.7416 - categorical_accuracy: 0.2090\n",
      "Epoch 00012: saving model to model_init_2021-07-0511_47_52.386877/model-00012-2.74158-0.20896-1.57273-0.29000.h5\n",
      "67/67 [==============================] - 35s 526ms/step - loss: 2.7416 - categorical_accuracy: 0.2090 - val_loss: 1.5727 - val_categorical_accuracy: 0.2900\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.4089 - categorical_accuracy: 0.2239\n",
      "Epoch 00013: saving model to model_init_2021-07-0511_47_52.386877/model-00013-2.40891-0.22388-1.55162-0.28000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 35s 522ms/step - loss: 2.4089 - categorical_accuracy: 0.2239 - val_loss: 1.5516 - val_categorical_accuracy: 0.2800\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.5051 - categorical_accuracy: 0.2289\n",
      "Epoch 00014: saving model to model_init_2021-07-0511_47_52.386877/model-00014-2.50513-0.22886-1.50665-0.33000.h5\n",
      "67/67 [==============================] - 38s 564ms/step - loss: 2.5051 - categorical_accuracy: 0.2289 - val_loss: 1.5066 - val_categorical_accuracy: 0.3300\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.5286 - categorical_accuracy: 0.2438\n",
      "Epoch 00015: saving model to model_init_2021-07-0511_47_52.386877/model-00015-2.52862-0.24378-1.59493-0.27000.h5\n",
      "67/67 [==============================] - 35s 518ms/step - loss: 2.5286 - categorical_accuracy: 0.2438 - val_loss: 1.5949 - val_categorical_accuracy: 0.2700\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6743 - categorical_accuracy: 0.1891\n",
      "Epoch 00016: saving model to model_init_2021-07-0511_47_52.386877/model-00016-2.67433-0.18905-1.49964-0.36000.h5\n",
      "67/67 [==============================] - 36s 536ms/step - loss: 2.6743 - categorical_accuracy: 0.1891 - val_loss: 1.4996 - val_categorical_accuracy: 0.3600\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6542 - categorical_accuracy: 0.2438\n",
      "Epoch 00017: saving model to model_init_2021-07-0511_47_52.386877/model-00017-2.65421-0.24378-1.60468-0.25000.h5\n",
      "67/67 [==============================] - 37s 546ms/step - loss: 2.6542 - categorical_accuracy: 0.2438 - val_loss: 1.6047 - val_categorical_accuracy: 0.2500\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6614 - categorical_accuracy: 0.2090\n",
      "Epoch 00018: saving model to model_init_2021-07-0511_47_52.386877/model-00018-2.66136-0.20896-1.55773-0.31000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 37s 551ms/step - loss: 2.6614 - categorical_accuracy: 0.2090 - val_loss: 1.5577 - val_categorical_accuracy: 0.3100\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6731 - categorical_accuracy: 0.1841\n",
      "Epoch 00019: saving model to model_init_2021-07-0511_47_52.386877/model-00019-2.67311-0.18408-1.57941-0.26000.h5\n",
      "67/67 [==============================] - 36s 538ms/step - loss: 2.6731 - categorical_accuracy: 0.1841 - val_loss: 1.5794 - val_categorical_accuracy: 0.2600\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.7345 - categorical_accuracy: 0.1891\n",
      "Epoch 00020: saving model to model_init_2021-07-0511_47_52.386877/model-00020-2.73454-0.18905-1.54272-0.32000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "67/67 [==============================] - 36s 532ms/step - loss: 2.7345 - categorical_accuracy: 0.1891 - val_loss: 1.5427 - val_categorical_accuracy: 0.3200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0e55b7a6a0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 20\n",
    "model_f.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model G Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_18 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_21 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,749\n",
      "Trainable params: 3,667,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "classes = 5\n",
    "channel = 3\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "input_shape=(x,y,z,channel)\n",
    "\n",
    "# Define model\n",
    "model_g = Sequential()\n",
    "\n",
    "model_g.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_g.add(BatchNormalization())\n",
    "model_g.add(Activation('relu'))\n",
    "\n",
    "model_g.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_g.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_g.add(BatchNormalization())\n",
    "model_g.add(Activation('relu'))\n",
    "\n",
    "model_g.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_g.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_g.add(BatchNormalization())\n",
    "model_g.add(Activation('relu'))\n",
    "\n",
    "model_g.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_g.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_g.add(BatchNormalization())\n",
    "model_g.add(Activation('relu'))\n",
    "\n",
    "model_g.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_g.add(Flatten())\n",
    "\n",
    "model_g.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_g.add(Dropout(0.5))\n",
    "\n",
    "model_g.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_g.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_g.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_g.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n",
      "65/67 [============================>.] - ETA: 2s - loss: 3.4186 - categorical_accuracy: 0.1892Batch:  67 Index: 10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.4285 - categorical_accuracy: 0.1900Source path =  datasets/Project_data/val ; batch size = 10\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0511_47_52.386877/model-00001-3.42847-0.19005-1.65610-0.26000.h5\n",
      "67/67 [==============================] - 92s 1s/step - loss: 3.4285 - categorical_accuracy: 0.1900 - val_loss: 1.6561 - val_categorical_accuracy: 0.2600\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.1976 - categorical_accuracy: 0.1940\n",
      "Epoch 00002: saving model to model_init_2021-07-0511_47_52.386877/model-00002-3.19758-0.19403-1.74571-0.26000.h5\n",
      "67/67 [==============================] - 37s 553ms/step - loss: 3.1976 - categorical_accuracy: 0.1940 - val_loss: 1.7457 - val_categorical_accuracy: 0.2600\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.0655 - categorical_accuracy: 0.2289\n",
      "Epoch 00003: saving model to model_init_2021-07-0511_47_52.386877/model-00003-3.06550-0.22886-1.66644-0.22000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 38s 560ms/step - loss: 3.0655 - categorical_accuracy: 0.2289 - val_loss: 1.6664 - val_categorical_accuracy: 0.2200\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.9765 - categorical_accuracy: 0.1990\n",
      "Epoch 00004: saving model to model_init_2021-07-0511_47_52.386877/model-00004-2.97646-0.19900-1.72096-0.26000.h5\n",
      "67/67 [==============================] - 39s 580ms/step - loss: 2.9765 - categorical_accuracy: 0.1990 - val_loss: 1.7210 - val_categorical_accuracy: 0.2600\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.7900 - categorical_accuracy: 0.2338\n",
      "Epoch 00005: saving model to model_init_2021-07-0511_47_52.386877/model-00005-2.78999-0.23383-1.70492-0.26000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 2.7900 - categorical_accuracy: 0.2338 - val_loss: 1.7049 - val_categorical_accuracy: 0.2600\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.2160 - categorical_accuracy: 0.1741\n",
      "Epoch 00006: saving model to model_init_2021-07-0511_47_52.386877/model-00006-3.21598-0.17413-1.85368-0.18000.h5\n",
      "67/67 [==============================] - 38s 564ms/step - loss: 3.2160 - categorical_accuracy: 0.1741 - val_loss: 1.8537 - val_categorical_accuracy: 0.1800\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.0479 - categorical_accuracy: 0.1940\n",
      "Epoch 00007: saving model to model_init_2021-07-0511_47_52.386877/model-00007-3.04785-0.19403-1.73184-0.29000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 38s 572ms/step - loss: 3.0479 - categorical_accuracy: 0.1940 - val_loss: 1.7318 - val_categorical_accuracy: 0.2900\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.0126 - categorical_accuracy: 0.2537\n",
      "Epoch 00008: saving model to model_init_2021-07-0511_47_52.386877/model-00008-3.01259-0.25373-1.71797-0.27000.h5\n",
      "67/67 [==============================] - 38s 565ms/step - loss: 3.0126 - categorical_accuracy: 0.2537 - val_loss: 1.7180 - val_categorical_accuracy: 0.2700\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.8561 - categorical_accuracy: 0.2338\n",
      "Epoch 00009: saving model to model_init_2021-07-0511_47_52.386877/model-00009-2.85612-0.23383-1.72683-0.23000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 40s 590ms/step - loss: 2.8561 - categorical_accuracy: 0.2338 - val_loss: 1.7268 - val_categorical_accuracy: 0.2300\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.8526 - categorical_accuracy: 0.2388\n",
      "Epoch 00010: saving model to model_init_2021-07-0511_47_52.386877/model-00010-2.85257-0.23881-1.79855-0.23000.h5\n",
      "67/67 [==============================] - 38s 562ms/step - loss: 2.8526 - categorical_accuracy: 0.2388 - val_loss: 1.7986 - val_categorical_accuracy: 0.2300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d984984e0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 10\n",
    "model_g.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model H Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_22 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_23 (Conv3D)           (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 3, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,749\n",
      "Trainable params: 3,667,509\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "classes = 5\n",
    "channel = 3\n",
    "\n",
    "input_shape=(x,y,z,channel)\n",
    "\n",
    "# Define model\n",
    "model_h = Sequential()\n",
    "\n",
    "model_h.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_h.add(BatchNormalization())\n",
    "model_h.add(Activation('relu'))\n",
    "\n",
    "model_h.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_h.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_h.add(BatchNormalization())\n",
    "model_h.add(Activation('relu'))\n",
    "\n",
    "model_h.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_h.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_h.add(BatchNormalization())\n",
    "model_h.add(Activation('relu'))\n",
    "\n",
    "model_h.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_h.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_h.add(BatchNormalization())\n",
    "model_h.add(Activation('relu'))\n",
    "\n",
    "model_h.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_h.add(Flatten())\n",
    "\n",
    "model_h.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_h.add(Dropout(0.5))\n",
    "\n",
    "model_h.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_h.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_h.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_h.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_h.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-38-34ddb7ef3ac8>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Source path =  datasets/Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n",
      "65/67 [============================>.] - ETA: 2s - loss: 3.0415 - categorical_accuracy: 0.2215Batch:  67 Index: 10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.0449 - categorical_accuracy: 0.2202Source path =  datasets/Project_data/val ; batch size = 10\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0514_52_19.218304/model-00001-3.04492-0.22021-1.58914-0.21000.h5\n",
      "67/67 [==============================] - 91s 1s/step - loss: 3.0449 - categorical_accuracy: 0.2202 - val_loss: 1.5891 - val_categorical_accuracy: 0.2100\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.8164 - categorical_accuracy: 0.2637\n",
      "Epoch 00002: saving model to model_init_2021-07-0514_52_19.218304/model-00002-2.81640-0.26368-1.56729-0.22000.h5\n",
      "67/67 [==============================] - 38s 574ms/step - loss: 2.8164 - categorical_accuracy: 0.2637 - val_loss: 1.5673 - val_categorical_accuracy: 0.2200\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6478 - categorical_accuracy: 0.2289\n",
      "Epoch 00003: saving model to model_init_2021-07-0514_52_19.218304/model-00003-2.64777-0.22886-1.57139-0.20000.h5\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 2.6478 - categorical_accuracy: 0.2289 - val_loss: 1.5714 - val_categorical_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6531 - categorical_accuracy: 0.2388\n",
      "Epoch 00004: saving model to model_init_2021-07-0514_52_19.218304/model-00004-2.65315-0.23881-1.52606-0.32000.h5\n",
      "67/67 [==============================] - 39s 583ms/step - loss: 2.6531 - categorical_accuracy: 0.2388 - val_loss: 1.5261 - val_categorical_accuracy: 0.3200\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.9547 - categorical_accuracy: 0.1791\n",
      "Epoch 00005: saving model to model_init_2021-07-0514_52_19.218304/model-00005-2.95469-0.17910-1.55950-0.29000.h5\n",
      "67/67 [==============================] - 41s 610ms/step - loss: 2.9547 - categorical_accuracy: 0.1791 - val_loss: 1.5595 - val_categorical_accuracy: 0.2900\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.9073 - categorical_accuracy: 0.1791\n",
      "Epoch 00006: saving model to model_init_2021-07-0514_52_19.218304/model-00006-2.90729-0.17910-1.59311-0.26000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 2.9073 - categorical_accuracy: 0.1791 - val_loss: 1.5931 - val_categorical_accuracy: 0.2600\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.7722 - categorical_accuracy: 0.2488\n",
      "Epoch 00007: saving model to model_init_2021-07-0514_52_19.218304/model-00007-2.77220-0.24876-1.62846-0.29000.h5\n",
      "67/67 [==============================] - 37s 557ms/step - loss: 2.7722 - categorical_accuracy: 0.2488 - val_loss: 1.6285 - val_categorical_accuracy: 0.2900\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6732 - categorical_accuracy: 0.2239\n",
      "Epoch 00008: saving model to model_init_2021-07-0514_52_19.218304/model-00008-2.67322-0.22388-1.58172-0.33000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 38s 564ms/step - loss: 2.6732 - categorical_accuracy: 0.2239 - val_loss: 1.5817 - val_categorical_accuracy: 0.3300\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.6930 - categorical_accuracy: 0.2189\n",
      "Epoch 00009: saving model to model_init_2021-07-0514_52_19.218304/model-00009-2.69303-0.21891-1.67112-0.26000.h5\n",
      "67/67 [==============================] - 39s 586ms/step - loss: 2.6930 - categorical_accuracy: 0.2189 - val_loss: 1.6711 - val_categorical_accuracy: 0.2600\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 2.9356 - categorical_accuracy: 0.1841\n",
      "Epoch 00010: saving model to model_init_2021-07-0514_52_19.218304/model-00010-2.93560-0.18408-1.60524-0.30000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 38s 562ms/step - loss: 2.9356 - categorical_accuracy: 0.1841 - val_loss: 1.6052 - val_categorical_accuracy: 0.3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe508640e80>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 10\n",
    "model_h.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model I Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,493\n",
      "Trainable params: 3,667,381\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height \n",
    "\n",
    "classes = 5\n",
    "channel = 3\n",
    "\n",
    "input_shape=(x,y,z,channel)\n",
    "\n",
    "# Define model\n",
    "model_i = Sequential()\n",
    "\n",
    "model_i.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_i.add(BatchNormalization())\n",
    "model_i.add(Activation('relu'))\n",
    "\n",
    "model_i.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_i.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_i.add(BatchNormalization())\n",
    "model_i.add(Activation('relu'))\n",
    "\n",
    "model_i.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_i.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_i.add(BatchNormalization())\n",
    "model_i.add(Activation('relu'))\n",
    "\n",
    "model_i.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_i.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_i.add(Activation('relu'))\n",
    "model_i.add(Dropout(0.25))\n",
    "\n",
    "model_i.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_i.add(Flatten())\n",
    "\n",
    "model_i.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_i.add(Dropout(0.5))\n",
    "\n",
    "model_i.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_i.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_i.add(Dense(nb_dense[2], activation='softmax'))\n",
    "model_i.compile(optimizer=keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_i.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n",
      "65/67 [============================>.] - ETA: 2s - loss: 4.2266 - categorical_accuracy: 0.1846Batch:  67 Index: 10\n",
      "67/67 [==============================] - ETA: 0s - loss: 4.2111 - categorical_accuracy: 0.1855Source path =  datasets/Project_data/val ; batch size = 10\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0515_14_59.816322/model-00001-4.21114-0.18552-1.66875-0.20000.h5\n",
      "67/67 [==============================] - 90s 1s/step - loss: 4.2111 - categorical_accuracy: 0.1855 - val_loss: 1.6687 - val_categorical_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.8889 - categorical_accuracy: 0.1841\n",
      "Epoch 00002: saving model to model_init_2021-07-0515_14_59.816322/model-00002-3.88888-0.18408-1.69613-0.20000.h5\n",
      "67/67 [==============================] - 38s 571ms/step - loss: 3.8889 - categorical_accuracy: 0.1841 - val_loss: 1.6961 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.8231 - categorical_accuracy: 0.2587\n",
      "Epoch 00003: saving model to model_init_2021-07-0515_14_59.816322/model-00003-3.82313-0.25871-1.71111-0.17000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 39s 587ms/step - loss: 3.8231 - categorical_accuracy: 0.2587 - val_loss: 1.7111 - val_categorical_accuracy: 0.1700\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.9662 - categorical_accuracy: 0.1294\n",
      "Epoch 00004: saving model to model_init_2021-07-0515_14_59.816322/model-00004-3.96619-0.12935-1.73107-0.22000.h5\n",
      "67/67 [==============================] - 38s 564ms/step - loss: 3.9662 - categorical_accuracy: 0.1294 - val_loss: 1.7311 - val_categorical_accuracy: 0.2200\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.4957 - categorical_accuracy: 0.2239\n",
      "Epoch 00005: saving model to model_init_2021-07-0515_14_59.816322/model-00005-3.49571-0.22388-1.76615-0.13000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 38s 560ms/step - loss: 3.4957 - categorical_accuracy: 0.2239 - val_loss: 1.7662 - val_categorical_accuracy: 0.1300\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.2095 - categorical_accuracy: 0.1990\n",
      "Epoch 00006: saving model to model_init_2021-07-0515_14_59.816322/model-00006-3.20954-0.19900-1.75075-0.21000.h5\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 3.2095 - categorical_accuracy: 0.1990 - val_loss: 1.7508 - val_categorical_accuracy: 0.2100\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.4385 - categorical_accuracy: 0.2239\n",
      "Epoch 00007: saving model to model_init_2021-07-0515_14_59.816322/model-00007-3.43851-0.22388-1.89801-0.16000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 38s 560ms/step - loss: 3.4385 - categorical_accuracy: 0.2239 - val_loss: 1.8980 - val_categorical_accuracy: 0.1600\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.6443 - categorical_accuracy: 0.1741\n",
      "Epoch 00008: saving model to model_init_2021-07-0515_14_59.816322/model-00008-3.64434-0.17413-1.81071-0.21000.h5\n",
      "67/67 [==============================] - 38s 566ms/step - loss: 3.6443 - categorical_accuracy: 0.1741 - val_loss: 1.8107 - val_categorical_accuracy: 0.2100\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.8627 - categorical_accuracy: 0.1592\n",
      "Epoch 00009: saving model to model_init_2021-07-0515_14_59.816322/model-00009-3.86268-0.15920-1.86059-0.18000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 39s 580ms/step - loss: 3.8627 - categorical_accuracy: 0.1592 - val_loss: 1.8606 - val_categorical_accuracy: 0.1800\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 3.0028 - categorical_accuracy: 0.2537\n",
      "Epoch 00010: saving model to model_init_2021-07-0515_14_59.816322/model-00010-3.00275-0.25373-1.79842-0.20000.h5\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 3.0028 - categorical_accuracy: 0.2537 - val_loss: 1.7984 - val_categorical_accuracy: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3e9d664710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "num_epochs = 10\n",
    "model_i.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(30,120,120,3)\n",
    "\n",
    "# Define model\n",
    "model_final = Sequential()\n",
    "\n",
    "model_final.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model_final.add(BatchNormalization())\n",
    "model_final.add(Activation('relu'))\n",
    "\n",
    "model_final.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_final.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model_final.add(BatchNormalization())\n",
    "model_final.add(Activation('relu'))\n",
    "\n",
    "model_final.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_final.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_final.add(BatchNormalization())\n",
    "model_final.add(Activation('relu'))\n",
    "\n",
    "model_final.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_final.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model_final.add(Activation('relu'))\n",
    "model_final.add(Dropout(0.25))\n",
    "\n",
    "model_final.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model_final.add(Flatten())\n",
    "\n",
    "model_final.add(Dense(nb_dense[0], activation='relu'))\n",
    "model_final.add(Dropout(0.5))\n",
    "\n",
    "model_final.add(Dense(nb_dense[1], activation='relu'))\n",
    "model_final.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model_final.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = keras.optimizers.Adam() #write your optimizer\n",
    "model_final.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_final.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n",
      "65/67 [============================>.] - ETA: 2s - loss: 1.9165 - categorical_accuracy: 0.2446Batch:  67 Index: 10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.9121 - categorical_accuracy: 0.2428Source path =  datasets/Project_data/val ; batch size = 10\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0515_14_59.816322/model-00001-1.91214-0.24284-1.60231-0.23000.h5\n",
      "67/67 [==============================] - 93s 1s/step - loss: 1.9121 - categorical_accuracy: 0.2428 - val_loss: 1.6023 - val_categorical_accuracy: 0.2300\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5850 - categorical_accuracy: 0.2886\n",
      "Epoch 00002: saving model to model_init_2021-07-0515_14_59.816322/model-00002-1.58498-0.28856-1.60293-0.25000.h5\n",
      "67/67 [==============================] - 42s 621ms/step - loss: 1.5850 - categorical_accuracy: 0.2886 - val_loss: 1.6029 - val_categorical_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5996 - categorical_accuracy: 0.2289\n",
      "Epoch 00003: saving model to model_init_2021-07-0515_14_59.816322/model-00003-1.59960-0.22886-1.54769-0.28000.h5\n",
      "67/67 [==============================] - 39s 588ms/step - loss: 1.5996 - categorical_accuracy: 0.2289 - val_loss: 1.5477 - val_categorical_accuracy: 0.2800\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5769 - categorical_accuracy: 0.2637\n",
      "Epoch 00004: saving model to model_init_2021-07-0515_14_59.816322/model-00004-1.57692-0.26368-1.48960-0.42000.h5\n",
      "67/67 [==============================] - 41s 615ms/step - loss: 1.5769 - categorical_accuracy: 0.2637 - val_loss: 1.4896 - val_categorical_accuracy: 0.4200\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5876 - categorical_accuracy: 0.2189\n",
      "Epoch 00005: saving model to model_init_2021-07-0515_14_59.816322/model-00005-1.58763-0.21891-1.44845-0.41000.h5\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 1.5876 - categorical_accuracy: 0.2189 - val_loss: 1.4485 - val_categorical_accuracy: 0.4100\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4687 - categorical_accuracy: 0.3682\n",
      "Epoch 00006: saving model to model_init_2021-07-0515_14_59.816322/model-00006-1.46872-0.36816-1.46160-0.31000.h5\n",
      "67/67 [==============================] - 41s 610ms/step - loss: 1.4687 - categorical_accuracy: 0.3682 - val_loss: 1.4616 - val_categorical_accuracy: 0.3100\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5161 - categorical_accuracy: 0.3682\n",
      "Epoch 00007: saving model to model_init_2021-07-0515_14_59.816322/model-00007-1.51605-0.36816-1.43942-0.44000.h5\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 1.5161 - categorical_accuracy: 0.3682 - val_loss: 1.4394 - val_categorical_accuracy: 0.4400\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4282 - categorical_accuracy: 0.3731\n",
      "Epoch 00008: saving model to model_init_2021-07-0515_14_59.816322/model-00008-1.42817-0.37313-1.26950-0.45000.h5\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 1.4282 - categorical_accuracy: 0.3731 - val_loss: 1.2695 - val_categorical_accuracy: 0.4500\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5130 - categorical_accuracy: 0.3085\n",
      "Epoch 00009: saving model to model_init_2021-07-0515_14_59.816322/model-00009-1.51305-0.30846-1.40922-0.44000.h5\n",
      "67/67 [==============================] - 41s 611ms/step - loss: 1.5130 - categorical_accuracy: 0.3085 - val_loss: 1.4092 - val_categorical_accuracy: 0.4400\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4512 - categorical_accuracy: 0.4080\n",
      "Epoch 00010: saving model to model_init_2021-07-0515_14_59.816322/model-00010-1.45123-0.40796-1.35469-0.46000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 1.4512 - categorical_accuracy: 0.4080 - val_loss: 1.3547 - val_categorical_accuracy: 0.4600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3e9d24fdd8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "model_final.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4646 - categorical_accuracy: 0.2935\n",
      "Epoch 00001: saving model to model_init_2021-07-0515_14_59.816322/model-00001-1.46459-0.29353-1.36525-0.43000.h5\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 1.4646 - categorical_accuracy: 0.2935 - val_loss: 1.3652 - val_categorical_accuracy: 0.4300\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3757 - categorical_accuracy: 0.3930\n",
      "Epoch 00002: saving model to model_init_2021-07-0515_14_59.816322/model-00002-1.37567-0.39303-1.37942-0.47000.h5\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 1.3757 - categorical_accuracy: 0.3930 - val_loss: 1.3794 - val_categorical_accuracy: 0.4700\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3293 - categorical_accuracy: 0.4378\n",
      "Epoch 00003: saving model to model_init_2021-07-0515_14_59.816322/model-00003-1.32927-0.43781-1.43511-0.39000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 1.3293 - categorical_accuracy: 0.4378 - val_loss: 1.4351 - val_categorical_accuracy: 0.3900\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3614 - categorical_accuracy: 0.4030\n",
      "Epoch 00004: saving model to model_init_2021-07-0515_14_59.816322/model-00004-1.36139-0.40299-1.30093-0.45000.h5\n",
      "67/67 [==============================] - 41s 610ms/step - loss: 1.3614 - categorical_accuracy: 0.4030 - val_loss: 1.3009 - val_categorical_accuracy: 0.4500\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2884 - categorical_accuracy: 0.4428\n",
      "Epoch 00005: saving model to model_init_2021-07-0515_14_59.816322/model-00005-1.28843-0.44279-1.25338-0.52000.h5\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 1.2884 - categorical_accuracy: 0.4428 - val_loss: 1.2534 - val_categorical_accuracy: 0.5200\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3205 - categorical_accuracy: 0.4229\n",
      "Epoch 00006: saving model to model_init_2021-07-0515_14_59.816322/model-00006-1.32049-0.42289-1.21338-0.51000.h5\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 1.3205 - categorical_accuracy: 0.4229 - val_loss: 1.2134 - val_categorical_accuracy: 0.5100\n",
      "Epoch 7/10\n",
      " 3/67 [>.............................] - ETA: 12s - loss: 1.3995 - categorical_accuracy: 0.4444"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "model_final.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 64\n",
      "Epoch 1/10\n",
      " 9/67 [===>..........................] - ETA: 6:13 - loss: 2.5138 - categorical_accuracy: 0.2083Batch:  11 Index: 64\n",
      "38/67 [================>.............] - ETA: 1:45 - loss: 1.9768 - categorical_accuracy: 0.2593Batch:  29 Index: 23\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.8006 - categorical_accuracy: 0.3034Source path =  datasets/Project_data/val ; batch size = 64\n",
      "Batch:  2 Index: 64\n",
      "Batch:  3 Index: 36\n",
      "Batch:  4 Index: 28\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0516_22_40.984452/model-00001-1.80063-0.30343-1.51209-0.30696.h5\n",
      "67/67 [==============================] - 245s 4s/step - loss: 1.8006 - categorical_accuracy: 0.3034 - val_loss: 1.5121 - val_categorical_accuracy: 0.3070\n",
      "Epoch 2/10\n",
      " 6/67 [=>............................] - ETA: 1:56 - loss: 1.4324 - categorical_accuracy: 0.4035Batch:  35 Index: 19\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3279 - categorical_accuracy: 0.4302Batch:  7 Index: 16\n",
      "\n",
      "Epoch 00002: saving model to model_init_2021-07-0516_22_40.984452/model-00002-1.32793-0.43018-1.54591-0.23864.h5\n",
      "67/67 [==============================] - 144s 2s/step - loss: 1.3279 - categorical_accuracy: 0.4302 - val_loss: 1.5459 - val_categorical_accuracy: 0.2386\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1621 - categorical_accuracy: 0.5075\n",
      "Epoch 00003: saving model to model_init_2021-07-0516_22_40.984452/model-00003-1.16207-0.50746-1.59519-0.30000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "67/67 [==============================] - 136s 2s/step - loss: 1.1621 - categorical_accuracy: 0.5075 - val_loss: 1.5952 - val_categorical_accuracy: 0.3000\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9599 - categorical_accuracy: 0.6260\n",
      "Epoch 00004: saving model to model_init_2021-07-0516_22_40.984452/model-00004-0.95992-0.62599-1.88672-0.30000.h5\n",
      "67/67 [==============================] - 135s 2s/step - loss: 0.9599 - categorical_accuracy: 0.6260 - val_loss: 1.8867 - val_categorical_accuracy: 0.3000\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8221 - categorical_accuracy: 0.6725\n",
      "Epoch 00005: saving model to model_init_2021-07-0516_22_40.984452/model-00005-0.82206-0.67252-1.38217-0.40000.h5\n",
      "67/67 [==============================] - 136s 2s/step - loss: 0.8221 - categorical_accuracy: 0.6725 - val_loss: 1.3822 - val_categorical_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7276 - categorical_accuracy: 0.7270\n",
      "Epoch 00006: saving model to model_init_2021-07-0516_22_40.984452/model-00006-0.72761-0.72695-1.19467-0.52500.h5\n",
      "67/67 [==============================] - 137s 2s/step - loss: 0.7276 - categorical_accuracy: 0.7270 - val_loss: 1.1947 - val_categorical_accuracy: 0.5250\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5849 - categorical_accuracy: 0.7726\n",
      "Epoch 00007: saving model to model_init_2021-07-0516_22_40.984452/model-00007-0.58493-0.77261-0.78756-0.72500.h5\n",
      "67/67 [==============================] - 134s 2s/step - loss: 0.5849 - categorical_accuracy: 0.7726 - val_loss: 0.7876 - val_categorical_accuracy: 0.7250\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4772 - categorical_accuracy: 0.8235\n",
      "Epoch 00008: saving model to model_init_2021-07-0516_22_40.984452/model-00008-0.47719-0.82353-0.89981-0.70000.h5\n",
      "67/67 [==============================] - 135s 2s/step - loss: 0.4772 - categorical_accuracy: 0.8235 - val_loss: 0.8998 - val_categorical_accuracy: 0.7000\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4598 - categorical_accuracy: 0.8349\n",
      "Epoch 00009: saving model to model_init_2021-07-0516_22_40.984452/model-00009-0.45976-0.83494-0.68488-0.75000.h5\n",
      "67/67 [==============================] - 135s 2s/step - loss: 0.4598 - categorical_accuracy: 0.8349 - val_loss: 0.6849 - val_categorical_accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2939 - categorical_accuracy: 0.9025\n",
      "Epoch 00010: saving model to model_init_2021-07-0516_22_40.984452/model-00010-0.29390-0.90255-1.30817-0.55000.h5\n",
      "67/67 [==============================] - 135s 2s/step - loss: 0.2939 - categorical_accuracy: 0.9025 - val_loss: 1.3082 - val_categorical_accuracy: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f54761cbda0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "\n",
    "\n",
    "model_final.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  datasets/Project_data/train ; batch size = 40\n",
      "Epoch 1/10\n",
      "15/67 [=====>........................] - ETA: 3:42 - loss: 0.2390 - categorical_accuracy: 0.9167Batch:  17 Index: 40\n",
      "44/67 [==================>...........] - ETA: 1:13 - loss: 0.2293 - categorical_accuracy: 0.9151Batch:  29 Index: 23\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2173 - categorical_accuracy: 0.9217Source path =  datasets/Project_data/val ; batch size = 40\n",
      "Batch:  3 Index: 40\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-07-0516_22_40.984452/model-00001-0.21730-0.92174-0.92560-0.67917.h5\n",
      "67/67 [==============================] - 229s 3s/step - loss: 0.2173 - categorical_accuracy: 0.9217 - val_loss: 0.9256 - val_categorical_accuracy: 0.6792\n",
      "Epoch 2/10\n",
      "12/67 [====>.........................] - ETA: 1:48 - loss: 0.1565 - categorical_accuracy: 0.9518Batch:  35 Index: 19\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1964 - categorical_accuracy: 0.9356\n",
      "Epoch 00002: saving model to model_init_2021-07-0516_22_40.984452/model-00002-0.19638-0.93562-0.53911-0.81500.h5\n",
      "67/67 [==============================] - 161s 2s/step - loss: 0.1964 - categorical_accuracy: 0.9356 - val_loss: 0.5391 - val_categorical_accuracy: 0.8150\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1748 - categorical_accuracy: 0.9412\n",
      "Epoch 00003: saving model to model_init_2021-07-0516_22_40.984452/model-00003-0.17475-0.94118-0.59473-0.83500.h5\n",
      "67/67 [==============================] - 173s 3s/step - loss: 0.1748 - categorical_accuracy: 0.9412 - val_loss: 0.5947 - val_categorical_accuracy: 0.8350\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1677 - categorical_accuracy: 0.9447\n",
      "Epoch 00004: saving model to model_init_2021-07-0516_22_40.984452/model-00004-0.16770-0.94469-0.59145-0.80000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "67/67 [==============================] - 174s 3s/step - loss: 0.1677 - categorical_accuracy: 0.9447 - val_loss: 0.5915 - val_categorical_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0965 - categorical_accuracy: 0.9684\n",
      "Epoch 00005: saving model to model_init_2021-07-0516_22_40.984452/model-00005-0.09647-0.96839-0.57679-0.82500.h5\n",
      "67/67 [==============================] - 170s 3s/step - loss: 0.0965 - categorical_accuracy: 0.9684 - val_loss: 0.5768 - val_categorical_accuracy: 0.8250\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0884 - categorical_accuracy: 0.9719\n",
      "Epoch 00006: saving model to model_init_2021-07-0516_22_40.984452/model-00006-0.08842-0.97191-0.62771-0.75500.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "67/67 [==============================] - 171s 3s/step - loss: 0.0884 - categorical_accuracy: 0.9719 - val_loss: 0.6277 - val_categorical_accuracy: 0.7550\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0718 - categorical_accuracy: 0.9781\n",
      "Epoch 00007: saving model to model_init_2021-07-0516_22_40.984452/model-00007-0.07179-0.97805-0.64312-0.80500.h5\n",
      "67/67 [==============================] - 174s 3s/step - loss: 0.0718 - categorical_accuracy: 0.9781 - val_loss: 0.6431 - val_categorical_accuracy: 0.8050\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0603 - categorical_accuracy: 0.9842\n",
      "Epoch 00008: saving model to model_init_2021-07-0516_22_40.984452/model-00008-0.06030-0.98420-0.67741-0.80500.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "67/67 [==============================] - 170s 3s/step - loss: 0.0603 - categorical_accuracy: 0.9842 - val_loss: 0.6774 - val_categorical_accuracy: 0.8050\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0518 - categorical_accuracy: 0.9842\n",
      "Epoch 00009: saving model to model_init_2021-07-0516_22_40.984452/model-00009-0.05181-0.98420-0.63991-0.83000.h5\n",
      "67/67 [==============================] - 157s 2s/step - loss: 0.0518 - categorical_accuracy: 0.9842 - val_loss: 0.6399 - val_categorical_accuracy: 0.8300\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0588 - categorical_accuracy: 0.9824\n",
      "Epoch 00010: saving model to model_init_2021-07-0516_22_40.984452/model-00010-0.05883-0.98244-0.66276-0.85000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "67/67 [==============================] - 161s 2s/step - loss: 0.0588 - categorical_accuracy: 0.9824 - val_loss: 0.6628 - val_categorical_accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5476124c50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 40\n",
    "num_epochs = 10\n",
    "\n",
    "train_generator = generator_ex(train_path, train_doc, batch_size)\n",
    "val_generator = generator_ex(val_path, val_doc, batch_size)\n",
    "\n",
    "\n",
    "model_final.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
